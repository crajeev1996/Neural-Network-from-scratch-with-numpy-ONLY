{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I have coded an entire L-layer Deep Neural Network framework with multi-class classification capability using just the numpy library for major computations. This project was aimed at understanding and implementing the machinery behind the basic deep neural network architecture. Some of this work has been inspired from Andrew Ng's Deep Learning Specialization which I recently completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we start by importing the necessary python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall test our custom designed network on two datasets.\n",
    "  1) MNIST dataset\n",
    "  2) cat vs non-cat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_catdata():\n",
    "    train_dataset = h5py.File('train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cat vs noncat data\n",
    "x_train, y_train, x_test, y_test, classes = load_catdata()\n",
    "y_train = y_train.T.reshape([-1])\n",
    "y_test = y_test.T.reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall now define and code all our primary and helper functions which shall implement the DNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data,img_no):\n",
    "    plot = plt.imshow(data[img_no], cmap=plt.get_cmap('gray'))\n",
    "    return\n",
    "\n",
    "def flatten_and_normalize(image_dataset):\n",
    "    \"\"\"\n",
    "    function to reshape n images (tensor) into a n column vectors (length*width,n) dimensional matrix.\n",
    "    \"\"\"\n",
    "    new_data = image_dataset.reshape(image_dataset.shape[0], -1).T\n",
    "    new_data = new_data / 255\n",
    "    return new_data\n",
    "    \n",
    "def sigmoid(x, gradient=False):\n",
    "    \"\"\"\n",
    "    function for finding the sigmoid of a linear activation value 'Z' when argument gradient = False \n",
    "    or the derivative of activated value 'A' when argument gradient = True\n",
    "    \"\"\"\n",
    "    if gradient == False:\n",
    "        # Here input x = Z (X.W + b)\n",
    "        return 1/(1+np.exp(-x))\n",
    "    else:\n",
    "        # Here  input x = A (g(z))\n",
    "        return x*(1-x)\n",
    "\n",
    "def relu(x, gradient=False):\n",
    "    \"\"\"\n",
    "    function for finding the relu activation of a linear activation value 'Z' when argument gradient = False \n",
    "    or the derivative of relu activated value 'A' when argument gradient = True\n",
    "    \"\"\"\n",
    "    if gradient == False:\n",
    "        # Here input x = Z (X.W + b)\n",
    "        return np.maximum(0,x)\n",
    "        #return np.tanh(z)\n",
    "    else:\n",
    "        # Here input x = A (g(z))\n",
    "        return np.ceil(np.minimum(np.maximum(0,x),1))\n",
    "        #return (1 - np.power(z, 2))\n",
    "        \n",
    "def tanh(x, gradient = False):\n",
    "    \"\"\"\n",
    "    function for finding the tanh activation of a linear activation value 'Z' when argument gradient = False \n",
    "    or the derivative of tanh activated value 'A' when argument gradient = True\n",
    "    \"\"\"\n",
    "    if gradient == False:\n",
    "        # Here input x = Z (X.W + b)\n",
    "        return np.tanh(x)\n",
    "    else:\n",
    "        # Here input x = A (g(z))\n",
    "        return (1 - np.power(x, 2))\n",
    "    \n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
    "    \n",
    "def init_param(Y, n_input, n_hiddens = [3]):\n",
    "    \"\"\"\n",
    "    function to initialize weight and bias parameters\n",
    "    \"\"\"\n",
    "    n_out = Y.shape[0]\n",
    "    n_hiddens.append(n_out)\n",
    "    n_layers = [n_input] + n_hiddens\n",
    "    params = {}\n",
    "    for i in range(1,len(n_layers)):\n",
    "        params['W'+str(i)] = np.random.randn(n_layers[i],n_layers[i-1])/np.sqrt(n_layers[i-1]) \n",
    "        params['b'+str(i)] = np.zeros((n_layers[i],1))\n",
    "    return params\n",
    "\n",
    "def forward_prop(X,params,activation = 'relu'):\n",
    "    \"\"\"\n",
    "    function implementing one forward pass accross the network\n",
    "    Returns the sigmoid activations of the output layer. \n",
    "    \"\"\"   \n",
    "    n_layers = len(params)//2 \n",
    "    memory = {}\n",
    "    A = X\n",
    "   \n",
    "    # forward prop for input and hidden layers\n",
    "    for i in range(1,n_layers):\n",
    "        memory['A'+str(i-1)] = A\n",
    "        # calculate Z = W.X\n",
    "        W = params['W'+str(i)]\n",
    "        b = params['b'+str(i)]\n",
    "        Z = np.dot(W,A)+ b\n",
    "        # adding Z to memory cache for backpropagation\n",
    "        memory['Z'+str(i)] = Z\n",
    "        memory['W'+str(i)] = W\n",
    "        memory['b'+str(i)] = b\n",
    "        if activation == 'relu':\n",
    "            # calculate the activation of Z\n",
    "            A = relu(Z)\n",
    "        elif activation == 'tanh':\n",
    "            # calculate the activation of Z\n",
    "            A = tanh(Z)\n",
    "    \n",
    "    #forward prop for output layer\n",
    "    memory['A'+str(n_layers-1)] = A\n",
    "    W = params['W'+str(n_layers)]\n",
    "    b = params['b'+str(n_layers)]\n",
    "    Z = np.dot(W,A)+ b\n",
    "    memory['Z'+str(n_layers)] = Z\n",
    "    memory['W'+str(n_layers)] = W\n",
    "    memory['b'+str(n_layers)] = b\n",
    "    # calculate the activation of output layer\n",
    "    A = softmax(Z)\n",
    "    return A,memory \n",
    "\n",
    "def softmax_loss(activation,y):\n",
    "    \"\"\"\n",
    "    function to calculate cross-entropy loss of activation matrix w.r.t a y-matrix\n",
    "    \"\"\"\n",
    "    m = y.shape[1]\n",
    "    return (-1/m)*np.sum(y*np.log(activation))\n",
    "\n",
    "def back_prop(out_activation,Y,cache,activation = 'relu'):\n",
    "    \"\"\"\n",
    "    function implementing back propagation accross the network\n",
    "    Returns gradients of W and b vectors w.r.t the cross-entropy loss. \n",
    "    \"\"\"  \n",
    "    n_layers = len(cache)//4\n",
    "    grads = {}\n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    ## computing gradients for output layer\n",
    "    # computing dL/dZ for output layer\n",
    "    dLdZ = out_activation - Y\n",
    "    \n",
    "    # computing dL/dW for output layer and entering into grads dictionary\n",
    "    A_prev = cache['A'+str(n_layers-1)]\n",
    "    dLdW = (np.dot(dLdZ,A_prev.T))/m\n",
    "    grads['dW'+str(n_layers)] = dLdW\n",
    "    \n",
    "    # computing dL/db for output layer and entering into grads dictionary\n",
    "    dLdb = (np.sum(dLdZ,axis = 1,keepdims = True))/m\n",
    "    grads['db'+str(n_layers)] = dLdb\n",
    "    \n",
    "    ## computing gradients for hidden layers\n",
    "    for i in reversed(range(1,n_layers)):\n",
    "        # computing dL/dZ\n",
    "        W = cache['W'+str(i+1)]\n",
    "        A = cache['A'+str(i)]\n",
    "        if activation == 'relu':\n",
    "            dLdZ = np.dot(W.T,dLdZ) * relu(A, gradient = True)\n",
    "        elif activation == 'tanh':\n",
    "            dLdZ = np.dot(W.T,dLdZ) * tanh(A, gradient = True)\n",
    "        \n",
    "        # computing dL/dW and entering into grads dictionary\n",
    "        A_prev = cache['A'+str(i-1)]\n",
    "        dLdW = (np.dot(dLdZ,A_prev.T))/m\n",
    "        grads['dW'+str(i)] = dLdW\n",
    "        \n",
    "        # computing dL/db and entering into grads dictionary\n",
    "        dLdb = (np.sum(dLdZ,axis = 1,keepdims = True))/m\n",
    "        grads['db'+str(i)] = dLdb \n",
    "        W = cache['W'+str(i)]\n",
    "    return grads\n",
    "        \n",
    "def nn_model(X, Y, n_hidden,activation = 'relu', alpha=0.0001, epochs=1000, init_params = None):\n",
    "    \"\"\"\n",
    "    Function implementing the training procedure of the deep neural network.\n",
    "    \"\"\"\n",
    "    if init_params == None:\n",
    "        # initinalize weight and bias parameters\n",
    "        params = init_param(Y,X.shape[0],n_hidden)\n",
    "    else:\n",
    "        params = init_params\n",
    "    for i in range(epochs):     \n",
    "        # forward pass\n",
    "        activation_out,cache = forward_prop(X,params,activation=activation)\n",
    "        \n",
    "        # compute loss\n",
    "        loss = softmax_loss(activation_out,Y)\n",
    "        \n",
    "        # back-propagation\n",
    "        gradients = back_prop(activation_out,Y,cache,activation=activation)\n",
    "        \n",
    "        # update parameters\n",
    "        n_layers = len(params)//2\n",
    "\n",
    "        for j in range(1,n_layers+1):\n",
    "            params['W'+str(j)] = params['W'+str(j)] - alpha * gradients['dW'+str(j)] \n",
    "            params['b'+str(j)] = params['b'+str(j)] - alpha * gradients['db'+str(j)]\n",
    "        \n",
    "        # printing loss value every 100 epochs\n",
    "        if i%100 == 0:\n",
    "            print('Epoch ',i,': Cost = ',loss)\n",
    "    return params\n",
    "\n",
    "def preprocess_y(Y_in): # Y_in should have shape (num_elements,)\n",
    "    Y = np.reshape(Y_in,newshape = (1,Y_in.shape[0]))\n",
    "    y_train_input = np.zeros((len(np.unique(Y)),Y.shape[1]))\n",
    "    unique_elements = list(np.unique(Y))\n",
    "    unique_elements_mapped = list(range(len(np.unique(Y))))\n",
    "    y_list = list(Y[0])\n",
    "    y_list_mapped = list(map(lambda x:unique_elements_mapped[np.where(unique_elements==x)[0][0]],y_list))\n",
    "    mapping = np.reshape(np.concatenate((np.array(unique_elements),np.array(unique_elements_mapped))),newshape=(2,len(unique_elements)))\n",
    "    for i in range(len(y_list)):\n",
    "        for j in range(len(unique_elements_mapped)):\n",
    "            if y_list_mapped[i] == unique_elements_mapped[j]:\n",
    "                y_train_input[j,i] = 1\n",
    "    return y_train_input,mapping\n",
    "        \n",
    "def predict(X,params):\n",
    "    activations,memory = forward_prop(X,params)\n",
    "    preds = np.zeros(activations.shape)\n",
    "    for i in range(activations.shape[1]):\n",
    "        temp = activations[:,i]\n",
    "        preds[np.argmax(temp),i] = 1\n",
    "    return np.argmax(preds,axis=0)\n",
    " \n",
    "def accuracy(preds,y):\n",
    "    tot = y.shape[0]\n",
    "    return np.sum(preds==y)/tot*100\n",
    "\n",
    "def save_params(dictionary,name):\n",
    "    pickle_out = open(name,\"wb\")\n",
    "    pickle.dump(dictionary,pickle_out)\n",
    "    pickle_out.close()\n",
    "    return\n",
    "\n",
    "def open_params(name):\n",
    "    pickle_in = open(name,\"rb\")\n",
    "    return pickle.load(pickle_in)\n",
    "\n",
    "def classify_instance(data,image_no,params):\n",
    "    if len(data.shape)==3:\n",
    "        image = data[image_no,:,:].reshape((1,data.shape[1],data.shape[2]))\n",
    "    else:\n",
    "        image = data[image_no,:,:,:].reshape((1,data.shape[1],data.shape[2],data.shape[3]))\n",
    "    image_norm = flatten_and_normalize(image)\n",
    "    plt.imshow(data[image_no,:,:],cmap=plt.get_cmap('gray'))\n",
    "    pred = predict(image_norm,params)[0]\n",
    "    print('The predicted class is ',pred)\n",
    "    return    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall test the show_image function which shows an image from the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the 6th image in x_train\n",
    "show_image(x_train,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've coded all our functions, we shall preprocess our data to input into our neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions: (784, 60000)\n",
      "Y_train dimensions: (10, 60000)\n"
     ]
    }
   ],
   "source": [
    "x_train_input = flatten_and_normalize(x_train)\n",
    "y_train_input,mapping = preprocess_y(y_train)\n",
    "print('X_train dimensions:',x_train_input.shape)\n",
    "print('Y_train dimensions:',y_train_input.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have already trained my network for about 1.5 hours and saved my parameters. We shall load these trained parameters for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_params = open_params(\"MNIST_params_12000.pickle\")\n",
    "cat_params = open_params(\"catvsnoncat_params_2400.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can start training the network using the nn_model function. I trained the network for 12000 epochs on the MNIST dataset to get my parameters mnist_params. Total training time was around 1.5 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : Cost =  0.6645060697135088\n",
      "Epoch  100 : Cost =  0.5451612180169071\n",
      "Epoch  200 : Cost =  0.4649588330186332\n",
      "Epoch  300 : Cost =  0.3955263459939174\n",
      "Epoch  400 : Cost =  0.33551329910614913\n",
      "Epoch  500 : Cost =  0.292495594957442\n",
      "Epoch  600 : Cost =  0.2549141938365787\n",
      "Epoch  700 : Cost =  0.2174846576171648\n",
      "Epoch  800 : Cost =  0.19301048329010767\n",
      "Epoch  900 : Cost =  0.13960675792042293\n",
      "Epoch  1000 : Cost =  0.1105245320052982\n",
      "Epoch  1100 : Cost =  0.09475257003169259\n",
      "Epoch  1200 : Cost =  0.07453093628158868\n",
      "Epoch  1300 : Cost =  0.06378998272510761\n",
      "Epoch  1400 : Cost =  0.054119056822700656\n",
      "Epoch  1500 : Cost =  0.046483447051926266\n",
      "Epoch  1600 : Cost =  0.04051600999066786\n",
      "Epoch  1700 : Cost =  0.03553816025986224\n",
      "Epoch  1800 : Cost =  0.03146131443280601\n",
      "Epoch  1900 : Cost =  0.027929278844826315\n",
      "Epoch  2000 : Cost =  0.025034966971407585\n",
      "Epoch  2100 : Cost =  0.022549110461506018\n",
      "Epoch  2200 : Cost =  0.020427826686482516\n",
      "Epoch  2300 : Cost =  0.01861373805494785\n"
     ]
    }
   ],
   "source": [
    "final_params = nn_model(x_train_input,y_train_input,n_hidden = [50,20],activation = 'relu',alpha=0.003,epochs=2400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall use our loaded parameter sets mnist_params and cat_params for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy: 95.76833333333333\n",
      "Test data accuracy: 95.28999999999999\n"
     ]
    }
   ],
   "source": [
    "y_test_input,mapping_test = preprocess_y(y_test)\n",
    "x_test_input = flatten_and_normalize(x_test)\n",
    "preds = predict(x_train_input,mnist_params)\n",
    "preds_test = predict(x_test_input,mnist_params)\n",
    "print('Training data accuracy:',accuracy(preds,y_train))\n",
    "print('Test data accuracy:',accuracy(preds_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the mnist_params set, we get a training accuracy of 95.76% and a testing accuracy of 95.28% on the MNIST dataset, which seems quite good. Convolutional neural networks can get to even higher accuracies due to their ability to detect edges and patterns in multiple areas of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the classify_instance function, you can visualize and even predict individual examples from the testing or training sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted class is  5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# second argument is the image number\n",
    "classify_instance(x_test,1879,mnist_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save_params(final_params,\"catvsnoncat_params_2400.pickle\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
